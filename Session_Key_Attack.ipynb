{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBaylb3fovwOcqXXBtvrZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konnnGit/Session_Key_Attack/blob/main/Session_Key_Attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CshAI8YLEWI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad\n",
        "from Crypto.Random import get_random_bytes\n",
        "\n",
        "# Encrypt a plaintext with a given key and random IV\n",
        "def encrypt_message(key, plaintext):\n",
        "    cipher = AES.new(key, AES.MODE_CBC)\n",
        "    return cipher.encrypt(pad(plaintext, AES.block_size))\n",
        "\n",
        "# Generate a dataset with variability\n",
        "def generate_dataset(size, keys, plaintexts):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for _ in range(size):\n",
        "        key = np.random.choice(keys)  # Randomly select a key\n",
        "        plaintext = np.random.choice(plaintexts)  # Randomly select a plaintext\n",
        "        ciphertext = encrypt_message(key, plaintext)\n",
        "        features.append(list(ciphertext[:16]))  # Use the first 16 bytes as features\n",
        "        labels.append(hash(key) % 10)  # Group labels by key hash\n",
        "    return features, labels\n",
        "\n",
        "# Parameters\n",
        "keys = [get_random_bytes(16) for _ in range(2)]  # 5 random keys\n",
        "plaintexts = [b\"REQUEST CLIMB TO FL370\", b\"UNABLE DUE TO TRAFFIC\",  b\"CLIMB TO AND MAINTAIN FL270\", b\"REPORT LEVEL FL270\",b\"REQUEST DIVE TO FL200\",  b\"DIVE TO AND MAINTAIN FL200\"]  # 4 plaintexts\n",
        "\n",
        "# Generate dataset\n",
        "features, labels = generate_dataset(20, keys, plaintexts)\n",
        "#print (features, labels)\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Define the classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"MLPClassifier\": MLPClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    #\"SVM\": SVC(kernel='rbf'),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    accuracy = clf.score(X_test, y_test)\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "updiPaUHrRvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DvNTBFG0PGCu"
      }
    }
  ]
}